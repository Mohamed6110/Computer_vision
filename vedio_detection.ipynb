{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521b8b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653fcf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=cv2.imread(r\"F:\\playing\\Cars34.png\",0)\n",
    "img=cv2.imread(r\"F:\\playing\\Cars34.png\",1)\n",
    "# print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074eb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"first_img\",img)\n",
    "# k=cv2.waitKey(0)\n",
    "# if k=='27':\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# elif k==ord('s'):\n",
    "#     cv2.imwrite('ncar.jpg',img)\n",
    "#     cv2.destroyAllWindows()\n",
    "cv2.imshow(\"first_img\",img)\n",
    "k=cv2.waitKey(5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15db773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "# fourcc=cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "# out=cv2.VideoWriter('output.avi',fourcc,20.0,(640,480))\n",
    "print(cap.isOpened())\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        # out.write(frame)\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame',gray)\n",
    "        if cv2.waitKey(1)==ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "         break\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33ceaf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img2=np.zeros((512,512,3),np.uint8)\n",
    "img2=cv2.line(img2,(0,0),(511,511),(255,0,0),5)\n",
    "img2=cv2.rectangle(img2,(30,30),(510,1510),(0,255,0),5)\n",
    "img2=cv2.arrowedLine(img2,(0,255),(256,256),(0,255,0),5)\n",
    "img2=cv2.circle(img2,(447,63),63,(0,0,255),-1)\n",
    "img2=cv2.ellipse(img2,(256,256),(100,50),0,0,90,(255,255,0),1)\n",
    "img2=cv2.putText(img2,'here is first thing',(10,500),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_4)\n",
    "img2=cv2.polylines(img2,[np.array([[10,10],[100,100],[200,200],[300,300]],np.int32)],True,(0,255,255),3)\n",
    "cv2.imshow(\"line\",img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e301d040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n",
      "800.0\n",
      "448.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.set(3,740)  # set width\n",
    "cap.set(4,780)  # set height\n",
    "print(cap.get(3))\n",
    "print(cap.get(4))\n",
    "print(cap.isOpened())\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        \n",
    "        # out.write(frame)\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame',gray)\n",
    "        if cv2.waitKey(1)==ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "         break\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45cf5b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n",
      "800.0\n",
      "448.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.set(3,740)  # set width\n",
    "cap.set(4,780)  # set height\n",
    "print(cap.get(3))\n",
    "print(cap.get(4))\n",
    "print(cap.isOpened())\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        # Get the current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # Format the date and time as a string\n",
    "        date_time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        # Put the date and time on the frame\n",
    "        cv2.putText(frame, date_time_str, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        # Draw a rectangle around the text\n",
    "        cv2.rectangle(frame, (1, 1), (400, 50), (255, 255, 0), 1)\n",
    "        #put hight and width on the frame\n",
    "        height, width = frame.shape[:2]\n",
    "        cv2.putText(frame, f\"Width: {width}, Height: {height}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        #detect edges\n",
    "        edges = cv2.Canny(frame, 100, 200)\n",
    "        # Show the edges\n",
    "        # cv2.imshow('Edges', edges)\n",
    "        # Draw a rectangle around the edges\n",
    "        cv2.rectangle(edges, (1, 1), (400, 50), (255, 255, 0), 1)\n",
    "        #show the edges with rectangle\n",
    "        # cv2.imshow('Edges with Rectangle', edges)\n",
    "        # Show the frame with date and time\n",
    "        # cv2.imshow('Frame with Date and Time', frame)\n",
    "        # out.write(frame)\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        # cv2.imshow('frame',gray)\n",
    "        #detect face\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, 'Face', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "        cv2.imshow('frame', frame)\n",
    "        #detect eyes\n",
    "        eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(frame, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Eye', (ex, ey - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        cv2.imshow('frame with Face and Eye Detection', frame)\n",
    "        if cv2.waitKey(1)==ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "         break\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f27fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#smile detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,480)  # set width\n",
    "cap.set(4,840)  # set hight\n",
    "print(cap.get(3))\n",
    "print(cap.get(4))\n",
    "print(cap.isOpened())\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()\n",
    "    if ret==True:\n",
    "        # Convert the frame to HSV color space\n",
    "        # hsv=cv2.cvtColor(frame,cv2.COLOR_RGB2HSV)\n",
    "        # # cv2.imshow('frame',frame)\n",
    "        # cv2.imshow('bgr55',hsv)\n",
    "        #detect ear\n",
    "        smile_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "        smile= smile_cascade.detectMultiScale(frame, scaleFactor=1.7, minNeighbors=20, minSize=(30, 30))\n",
    "        cv2.putText(frame,'Smile Detection',(10,30),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "        for (x,y,w,h) in smile:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(frame,'smile',(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.9,(0,255,0),2)\n",
    "        cv2.imshow('smile Detection', frame)\n",
    "        if cv2.waitKey(1)==ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d6862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# upper body detection\n",
    "import cv2\n",
    "import numpy as np  \n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)  # set width\n",
    "cap.set(4, 480)  # set height\n",
    "print(cap.get(3))\n",
    "print(cap.get(4))\n",
    "print(cap.isOpened())\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Load the smile cascade classifier\n",
    "        body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "        \n",
    "        # Detect body in the frame\n",
    "        bodys = body_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(50,50))\n",
    "        \n",
    "        # Draw rectangles around detected smiles\n",
    "        for (x, y, w, h) in bodys:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Body', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display the frame with detected smiles\n",
    "        cv2.imshow('Body Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c9ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflwo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
